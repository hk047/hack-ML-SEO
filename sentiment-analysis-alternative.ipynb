{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b5672e",
   "metadata": {},
   "source": [
    "# üß† What is Sentiment Analysis?\n",
    "\n",
    "Imagine you‚Äôre reading a news article and trying to guess how the writer feels about the topic. Is it cheerful and upbeat, or gloomy and critical? That‚Äôs what **sentiment analysis** does‚Äîit figures out the mood or opinion in a piece of text, labeling it as *positive*, *negative*, or *neutral*. Here are some examples:\n",
    "\n",
    "- üòä \"The company‚Äôs profits soared!\" ‚Üí **Positive** (sounds happy and successful).\n",
    "- üòü \"The economy is collapsing.\" ‚Üí **Negative** (sounds worrying and bad).\n",
    "- üòê \"The meeting is at 2 PM.\" ‚Üí **Neutral** (just a fact, no strong feelings).\n",
    "\n",
    "### Why Does Sentiment Analysis Matter?\n",
    "\n",
    "In the real world, sentiment analysis is a big deal:\n",
    "- **Companies** use it to see if customers love or hate their products by analyzing reviews.\n",
    "- **Investors** check news or social media to gauge how people feel about the markets.\n",
    "- **You** will use it to analyze how news articles \"feel\" about different subtopics‚Äîlike whether technology gets more positive coverage than politics.\n",
    "\n",
    "By the end of this notebook, you‚Äôll have the skills to uncover these emotional insights from data. Pretty cool, right?\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Option 1: Sentiment Analysis Using TextBlob\n",
    "\n",
    "Let‚Äôs start with **TextBlob**, a simple Python tool that‚Äôs perfect for beginners. It reads text and tells us how positive or negative it sounds. Think of it as a friendly assistant who can quickly scan an article and give you a thumbs-up or thumbs-down.\n",
    "\n",
    "### Step 1: Install and Import TextBlob\n",
    "\n",
    "Before we can use TextBlob, we need to set it up in our Colab environment.\n",
    "\n",
    "```python\n",
    "# Install TextBlob if it‚Äôs not already available in Colab\n",
    "!pip install textblob\n",
    "\n",
    "# Import the TextBlob class so we can use it\n",
    "from textblob import TextBlob\n",
    "```\n",
    "\n",
    "**What‚Äôs happening here?**\n",
    "- `!pip install textblob`: This command installs the TextBlob library. The `!` tells Colab to run it as a system command.\n",
    "- `from textblob import TextBlob`: This brings the TextBlob tool into our notebook, ready for action.\n",
    "\n",
    "**Why this matters:** We need to install and import TextBlob because it‚Äôs not built into Python by default. This step ensures we have the tools we need to analyze sentiment.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Try TextBlob on a Single Sentence\n",
    "\n",
    "Let‚Äôs test TextBlob with a simple sentence to see how it works.\n",
    "\n",
    "```python\n",
    "# Create a TextBlob object with a sample sentence\n",
    "blob = TextBlob(\"The market is doing terribly today.\")\n",
    "\n",
    "# Get the sentiment of the sentence\n",
    "sentiment = blob.sentiment\n",
    "\n",
    "# Print the result to see what TextBlob thinks\n",
    "print(sentiment)\n",
    "```\n",
    "\n",
    "**Sample Output:**\n",
    "```\n",
    "Sentiment(polarity=-1.0, subjectivity=1.0)\n",
    "```\n",
    "\n",
    "**What does this mean?**\n",
    "- **Polarity**: A number between -1 and +1 that shows how positive or negative the text is.\n",
    "  - -1 = very negative (like this example).\n",
    "  - 0 = neutral.\n",
    "  - +1 = very positive.\n",
    "- **Subjectivity**: A number between 0 and 1 that shows how opinionated the text is.\n",
    "  - 0 = very factual (like a weather report).\n",
    "  - 1 = very opinionated (like this sentence).\n",
    "\n",
    "Here, the polarity is -1.0 (very negative), and subjectivity is 1.0 (very opinionated), which fits because the sentence expresses a strong negative feeling.\n",
    "\n",
    "**Let‚Äôs experiment!** Try these sentences by replacing the text in the code above:\n",
    "- üòä \"I love this new technology!\"\n",
    "- üòê \"The sky is blue.\"\n",
    "- üòü \"This is the worst day ever.\"\n",
    "\n",
    "What polarity and subjectivity do you expect? Run the code and check!\n",
    "\n",
    "**Why this matters:** Testing single sentences helps us get comfortable with TextBlob. It‚Äôs like peeking under the hood of a car before driving it‚Äîwe understand how it works before using it on our whole dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Apply TextBlob to the News Articles\n",
    "\n",
    "Now that we‚Äôve practiced, let‚Äôs use TextBlob on our dataset of news articles. We‚Äôll assume your dataset is loaded into a DataFrame called `df` with a column named `Description` (if your column names are different, adjust accordingly!).\n",
    "\n",
    "```python\n",
    "# Apply TextBlob to each article‚Äôs description and store the polarity in a new column\n",
    "df['Sentiment_Polarity'] = df['Description'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "```\n",
    "\n",
    "**What‚Äôs happening here?**\n",
    "- `df['Description']`: This selects the `Description` column, where each row is an article‚Äôs text.\n",
    "- `.apply(lambda x: ...)`: This runs the same function on every row. The `lambda x` is a small, temporary function that takes each description (`x`) and processes it.\n",
    "- `TextBlob(x).sentiment.polarity`: This calculates the polarity for each description.\n",
    "- `df['Sentiment_Polarity']`: This creates a new column to save the polarity scores.\n",
    "\n",
    "**Check your work:** Run `df.head()` to see the first few rows. Do the polarity scores match the tone of the descriptions?\n",
    "\n",
    "**Why this matters:** Adding a sentiment score to each article lets us analyze the emotions across the dataset. Now we can ask big questions, like which subtopics are covered more positively or negatively. This is the heart of our project!\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Reflect and Discuss\n",
    "\n",
    "TextBlob is easy to use, but it‚Äôs not perfect. Let‚Äôs think about its limits:\n",
    "- **Can it always get the sentiment right?** What about sarcasm, like \"Great, another market crash...\"? (Spoiler: It might think \"great\" is positive!)\n",
    "- **Does it work well with short texts?** Like headlines or tweets?\n",
    "- **What about complex emotions?** Can it tell if someone‚Äôs joking?\n",
    "\n",
    "**üß† Reflection Prompt:**  \n",
    "When might TextBlob struggle to understand the true tone of a sentence? Why? Think of an example where the words sound positive but the meaning is negative‚Äîor the other way around.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Option 2: Sentiment Analysis Using Hugging Face Transformers\n",
    "\n",
    "Ready to level up? Let‚Äôs try **Hugging Face Transformers**, a more advanced tool that‚Äôs like a super-smart AI. It‚Äôs trained on tons of text, so it can pick up on nuances that TextBlob might miss.\n",
    "\n",
    "### What Are Transformers?\n",
    "\n",
    "Think of TextBlob as a basic dictionary that knows some words and their feelings. Transformers are like expert English teachers who‚Äôve read millions of books and can understand tone, context, and even hidden meanings. They‚Äôre more powerful because they‚Äôve been trained on massive amounts of data.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Install and Set Up Hugging Face Transformers\n",
    "\n",
    "First, we need to install the transformers library and bring in the tools we‚Äôll use.\n",
    "\n",
    "```python\n",
    "# Install the transformers library\n",
    "!pip install transformers\n",
    "\n",
    "# Import the pipeline function, which makes using transformers easy\n",
    "from transformers import pipeline\n",
    "```\n",
    "\n",
    "**What‚Äôs happening here?**\n",
    "- `!pip install transformers`: This installs the transformers library in Colab.\n",
    "- `from transformers import pipeline`: This imports a handy tool called `pipeline` that simplifies working with pretrained models.\n",
    "\n",
    "**Why this matters:** We need these tools to access the power of transformers. This step sets us up for advanced sentiment analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Load a Pretrained Sentiment Analysis Model\n",
    "\n",
    "Hugging Face offers ready-to-use models. Let‚Äôs load one designed for sentiment analysis.\n",
    "\n",
    "```python\n",
    "# Create a sentiment analysis pipeline with a pretrained model\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "```\n",
    "\n",
    "**What‚Äôs happening here?**\n",
    "- `pipeline(\"sentiment-analysis\")`: This sets up a pipeline that uses a pretrained model to analyze sentiment. It‚Äôs like hiring an expert who‚Äôs already trained and ready to work!\n",
    "\n",
    "**Why this matters:** Using a pretrained model saves us time and effort. It‚Äôs already learned how to detect emotions from tons of text, so we can jump straight to using it.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Try the Model on One Example\n",
    "\n",
    "Let‚Äôs test the transformer model with a single sentence.\n",
    "\n",
    "```python\n",
    "# Analyze a sample sentence\n",
    "result = sentiment_model(\"The new technology is breaking boundaries.\")\n",
    "\n",
    "# Print the result\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Sample Output:**\n",
    "```\n",
    "[{'label': 'POSITIVE', 'score': 0.9998}]\n",
    "```\n",
    "\n",
    "**What does this mean?**\n",
    "- **Label**: The model predicts \"POSITIVE\" or \"NEGATIVE.\"\n",
    "- **Score**: A number between 0 and 1 showing how confident the model is (here, 99.98% sure it‚Äôs positive).\n",
    "\n",
    "**Try it yourself:** Test \"This product is terrible.\" What label and score do you get?\n",
    "\n",
    "**Why this matters:** The confidence score helps us trust the model‚Äôs judgment. A high score means it‚Äôs very sure, while a low score (like 0.5) might mean the text is tricky. Testing it builds our understanding before we scale up.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Apply the Model to the Whole Dataset\n",
    "\n",
    "Now, let‚Äôs use the transformer model on all our articles‚Äô descriptions.\n",
    "\n",
    "```python\n",
    "# Apply the sentiment model to each description\n",
    "df['HF_Sentiment'] = df['Description'].apply(lambda x: sentiment_model(x)[0])\n",
    "\n",
    "# Split the result into two columns: label and score\n",
    "df['HF_Sentiment_Label'] = df['HF_Sentiment'].apply(lambda x: x['label'])\n",
    "df['HF_Sentiment_Score'] = df['HF_Sentiment'].apply(lambda x: x['score'])\n",
    "```\n",
    "\n",
    "**What‚Äôs happening here?**\n",
    "- `sentiment_model(x)[0]`: The model returns a list with one dictionary per description. We take the first item (`[0]`).\n",
    "- `df['HF_Sentiment']`: This temporarily stores the full result.\n",
    "- We then extract:\n",
    "  - `HF_Sentiment_Label`: The prediction (\"POSITIVE\" or \"NEGATIVE\").\n",
    "  - `HF_Sentiment_Score`: The confidence score.\n",
    "\n",
    "**Check your work:** Run `df.head()` to see the new columns. Do the labels match the descriptions‚Äô tones?\n",
    "\n",
    "**Why this matters:** Using a second model lets us compare approaches. Does Hugging Face agree with TextBlob? If not, why? This comparison makes our analysis stronger and more reliable.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Reflect and Discuss\n",
    "\n",
    "Transformers are advanced, but they‚Äôre not flawless. Let‚Äôs think about them:\n",
    "- **What‚Äôs better about this model?** It understands context‚Äîlike \"not good\" being negative‚Äîbetter than TextBlob.\n",
    "- **Can it still mess up?** Yes, especially with sarcasm or niche topics it wasn‚Äôt trained on.\n",
    "- **Which model do you trust more?** If they disagree, why might that happen?\n",
    "\n",
    "**üéÅ Bonus Idea:**  \n",
    "Try feeding both models a sarcastic sentence like \"Oh great, another delay.\" Which one gets it right? Run the test and find out!\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Analyze Sentiment by Subtopic\n",
    "\n",
    "We‚Äôve got sentiment scores from both models‚Äînow let‚Äôs use them to answer our big question: Which subtopics have more positive or negative coverage?\n",
    "\n",
    "### Step 1: Group by Subtopic and Calculate Average Sentiment\n",
    "\n",
    "Let‚Äôs start with TextBlob‚Äôs polarity scores.\n",
    "\n",
    "```python\n",
    "# Group articles by subtopic and calculate the average polarity\n",
    "avg_sentiment = df.groupby('Subtopic')['Sentiment_Polarity'].mean().sort_values()\n",
    "```\n",
    "\n",
    "**What‚Äôs happening here?**\n",
    "- `df.groupby('Subtopic')`: This organizes the data by subtopic (from Part 1‚Äôs clustering).\n",
    "- `['Sentiment_Polarity'].mean()`: This averages the polarity scores for each subtopic.\n",
    "- `.sort_values()`: This sorts from most negative to most positive.\n",
    "\n",
    "**Why this matters:** This step turns our raw scores into actionable insights. We can now see which subtopics are the most positive or negative overall‚Äîour main goal!\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Plot the Results\n",
    "\n",
    "Let‚Äôs visualize this with a bar chart using seaborn, a library that makes plots look great.\n",
    "\n",
    "```python\n",
    "# Import libraries for plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plot size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a bar plot of average sentiment by subtopic\n",
    "sns.barplot(x=avg_sentiment.values, y=avg_sentiment.index, palette=\"coolwarm\")\n",
    "\n",
    "# Add clear labels and a title\n",
    "plt.title(\"Average Sentiment by Subtopic (TextBlob)\")\n",
    "plt.xlabel(\"Average Sentiment Polarity (-1 to +1)\")\n",
    "plt.ylabel(\"Subtopic\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**What‚Äôs happening here?**\n",
    "- `sns.barplot()`: This draws bars where the length shows the average polarity, and the y-axis lists subtopics.\n",
    "- `palette=\"coolwarm\"`: Colors range from red (negative) to blue (positive).\n",
    "- Labels and title make it clear what we‚Äôre looking at.\n",
    "\n",
    "**Why this matters:** A chart makes it easy to spot patterns‚Äîlike which subtopics are positive or negative‚Äîat a glance. Bar charts are perfect for comparing categories like this.\n",
    "\n",
    "**üß† Reflection Prompt:**  \n",
    "Were you surprised by which subtopics had the most positive or negative coverage? Why might that be?\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Compare with Hugging Face Results\n",
    "\n",
    "Let‚Äôs analyze the Hugging Face results too, focusing on the percentage of positive articles per subtopic.\n",
    "\n",
    "```python\n",
    "# Calculate the percentage of articles labeled \"POSITIVE\" per subtopic\n",
    "positive_percentage = df.groupby('Subtopic')['HF_Sentiment_Label'].apply(lambda x: (x == 'POSITIVE').mean() * 100).sort_values()\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x=positive_percentage.values, y=positive_percentage.index, palette=\"viridis\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Percentage of Positive Articles by Subtopic (Hugging Face)\")\n",
    "plt.xlabel(\"Percentage of Positive Articles (%)\")\n",
    "plt.ylabel(\"Subtopic\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**What‚Äôs happening here?**\n",
    "- `(x == 'POSITIVE').mean() * 100`: This calculates the fraction of \"POSITIVE\" labels per subtopic, then converts it to a percentage.\n",
    "- The plot shows how many articles per subtopic are positive according to Hugging Face.\n",
    "\n",
    "**Why this matters:** This gives us a different angle‚Äîfocusing on positivity rates rather than average scores. Comparing both models helps us see the full picture.\n",
    "\n",
    "---\n",
    "\n",
    "## üó£ Visual Storytelling & Interpretation\n",
    "\n",
    "You‚Äôve got the data‚Äînow let‚Äôs tell a story with it! Create 1‚Äì2 new charts to explore further. Ideas:\n",
    "- Compare TextBlob‚Äôs average polarity with Hugging Face‚Äôs positive percentage.\n",
    "- Show the spread of sentiment scores for one subtopic (e.g., using a histogram).\n",
    "\n",
    "**Tips for Awesome Charts:**\n",
    "- **Label axes** clearly (e.g., \"Sentiment Score\" or \"Subtopic\").\n",
    "- **Add a title** that explains the chart‚Äôs purpose.\n",
    "- **Pick colors** that make sense (green for positive, red for negative).\n",
    "- **Keep it honest**‚Äîdon‚Äôt stretch the y-axis to exaggerate differences.\n",
    "\n",
    "**üß† Reflection Prompt:**  \n",
    "What story do your charts tell? If you were presenting this to a team, what would your headline be? Example: \"Tech News Shines Bright While Politics Dims.\"\n",
    "\n",
    "---\n",
    "\n",
    "## üí¨ Final Discussion & Extensions\n",
    "\n",
    "Amazing work! Let‚Äôs wrap up with some big questions:\n",
    "- **Are these models biased?** Do they favor certain words or topics? How could we test that?\n",
    "- **Do they treat all subtopics fairly?** Maybe some topics naturally use more emotional language.\n",
    "- **What about article length?** Do short headlines or long articles work better?\n",
    "\n",
    "**üéÅ Bonus Idea:**  \n",
    "Combine the `Title` and `Description` into one text (e.g., `df['Title'] + \" \" + df['Description']`) and rerun the sentiment analysis. Does adding the title improve the results?\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Final Deliverables\n",
    "\n",
    "To finish Part 2, prepare these for your hackathon submission:\n",
    "- ‚úÖ **What your models do:** Explain how TextBlob and Hugging Face analyze sentiment.\n",
    "- üìä **Visualizations:** Include at least two charts showing your insights.\n",
    "- ü§î **Reflections:** Share what worked, what didn‚Äôt, and what surprised you.\n",
    "- üõ† **One improvement:** Suggest something you‚Äôd try with more time (e.g., testing more models).\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You‚Äôve just completed a real-world sentiment analysis project! You‚Äôve learned to use two powerful tools, compare their results, and turn data into a story with charts. Even better, you‚Äôre thinking like a data scientist‚Äîasking questions, experimenting, and reflecting.\n",
    "\n",
    "Keep exploring and stay curious. The skills you‚Äôve gained here are the start of something big. The tech world is lucky to have you! üåü"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
